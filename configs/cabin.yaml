# Prompt
text: 'A large cabin on top of a sunny mountain in the style of Dreamworks, artstation'  # text prompt
negative: ''  # negative text prompt

# Training Settings
test: False  # set to True for test mode
save_mesh: False  # set to True to export an OBJ mesh with texture
eval_interval: 200  # evaluate on the validation set every N epochs
seed: 12  # random seed for reproducibility
iters: 10000  # number of training iterations
lr: 1.0e-3  # initial learning rate
ckpt: 'latest'  # checkpoint to start training from (e.g., latest checkpoint)
fp16: True  # use mixed precision (fp16) to save memory and improve speed
backbone: 'grid_finite'  # NeRF backbone type (grid-based representation)

# Neural Graphics Primitives (NGP)
cuda_ray: False  # set to True if CUDA raymarching is supported on your system
max_steps: 1024  # maximum steps per ray (valid if cuda_ray is True)
num_steps: 64  # number of steps per ray (if not using CUDA raymarching)
upsample_steps: 64  # number of upsampled steps per ray
update_extra_interval: 16  # update extra status interval (when using CUDA raymarching)
max_ray_batch: 4096  # batch size for rays to avoid OOM errors during inference
albedo_iters: 400  # iterations for training using only albedo shading
bg_radius: 1.4  # radius for background model (if positive, use a background sphere)
density_activation: 'exp'  # activation function for density
density_thresh: 0.1  # density threshold for occupancy
lambda_tv: 0  # total variation loss scale
p_albedo: 0.25  # probability of using albedo for training
p_textureless: 0.5  # probability of using textureless rendering
p_randbg: 0.75  # probability of using random backgrounds

# Residual Blob Settings
blob_density: 5  # max center density for the density blob
blob_radius: 0.2  # radius for the density blob

# Camera Settings
w: 128  # render width for NeRF during training
h: 128  # render height for NeRF during training
normal_shape: 100  # height for normal rendering
jitter_pose: True  # add jitter to camera poses for data augmentation
bound: 1  # bounding box limits (-bound to bound)
dt_gamma: 0  # adaptive ray marching (0 disables it)
min_near: 0.1  # minimum near distance for camera
radius_range: [0.4, 1.0]  # camera radius range during training
fovy_range: [40, 70]  # field of view range during training

# Directional Text Encoding
dir_text: True  # use direction-encoded text prompts (e.g., front, side, back views)
negative_dir_text: False  # also use negative direction text prompts
angle_overhead: 30  # overhead angle range for view sampling
angle_front: 60  # front angle range for view sampling

# Loss Function Weights
lambda_entropy: 0  # alpha entropy loss scale
lambda_opacity: 1.0e-3  # opacity loss scale
lambda_orient: 10  # orientation loss scale
lambda_smooth: 0  # smoothness loss scale
lambda_blur: 0  # blur loss scale
distortion: 0.1  # distortion loss for MipNeRF360

# Test-Time Rendering Settings
gui: False  # enable GUI for testing
W: 800  # width for test-time rendering
H: 800  # height for test-time rendering
fovy: 60  # field of view for the camera during testing

# Reference View Settings
mask_path: 'data/cabin4_centered_mask.png'  # path to the mask file
depth_path: 'data/cabin4_centered.npy'  # path to the depth map file
rgb_path: 'data/cabin4_centered.png'  # path to the RGB image file
warmup_epoch: 1  # number of warmup epochs
init_theta: 90  # initial theta angle for the camera
init_radius: 0.4  # initial camera radius
front_fov: 60  # field of view for the front view
clip_img_weight: 1  # weight for the CLIP image loss
front_ratio: 0.02  # ratio for reference views during training
front_dist_amplify: 10  # amplification factor for distance
front_dsmooth_amplify: 5  # amplification factor for depth smoothness
ref_perturb_prob: 0.05  # probability for perturbing reference views
ref_rgb_weight: 40  # weight for reference RGB loss

# Diffusion Model Guidance
guidance: sd_clipguide  # guidance method using Stable Diffusion + CLIP
min_sd: 50  # minimum diffusion timestep
max_sd: 950  # maximum diffusion timestep
eta: 0.8  # classifier-free guidance scale
dataset: text2img  # dataset type (text-to-image)
sd_name: runwayml/stable-diffusion-v1-5  # pre-trained Stable Diffusion model
